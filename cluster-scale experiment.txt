Experiment with scripted cluster autoscaler
===========================================

The requirement
---------------

The wish is that we can setup an environment to run the "hpa-php-apache + load" environment
on a k8s cluster just by scripting (except perhaps the load generator). When the loading starts,
the number of pods should increase as required. When the load is turned off, it should
decrease. The apache pods should run on their own t3.micro-based nodegroup. This should
have min 1. (Stretch goal, the nodegroup has min size 0 and should have no associated nodes
until the apache deployment is made)

Some notes
----------

* The cluster scaler deployments need at least 600m so won't run on a t3.micro node. Need to
at least allocated t3.small (the exercise before was m5.large)
* Assume we will use taint and toleration wrt to the new nodegroup.
* The deployment for the autoscaler in instructions to date seems finickity in that the
deployment script (so far https://raw.githubusercontent.com/kubernetes/autoscaler/refs/heads/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-autodiscover.yaml) requires manual edit following deployment. Ideally want helm chart
but even then it requires knowledge of the current kubenetes version and the latest
deployment image for that.

Basic Approach
--------------

* Want cluster with managed nodes for the system pods, including autoscalers. Must
be at least "small" - so use t3.small. Make "managed" for good measure but not sure required.
* Create managed nodegroup for the app running t3.mobile. "ng-nginx"


Possible script
---------------

eksctl create cluster --name eksctl-test --nodegroup-name ng-default --node-type t3.small --nodes 2 --managed
(don't use config file because that creates two cloudformation jobs and the delete does not work)
eksctl create nodegroup -f eks-create-app-ng.yml
(note min size set to 0 and desired size to 1 - we want a node to start with as that forms the template,
otherwise we need to add extra node-template labels to the nodegroup.

helm repo add autoscaler https://kubernetes.github.io/autoscaler
helm install autosc-release autoscaler/cluster-autoscaler \
    --set 'autoDiscovery.clusterName'=eksctl-test

        status code: 403, request id: cf498e20-b6e8-4d4d-8139-1829716246c6
F0410 22:59:36.344254       1 aws_cloud_provider.go:466] Failed to create AWS Manager: AccessDenied: User: arn:aws:sts::288580320153:assumed-role/eksctl-eksctl-test-nodegroup
-ng-de-NodeInstanceRole-4hYTyI4M3gRK/i-0df1d6cd6c4ec2e3e is not authorized to perform: autoscaling:DescribeAutoScalingGroups because no identity-based policy allows the autos
caling:DescribeAutoScalingGroups action
